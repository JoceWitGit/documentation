
Python has a Library to help simplify connecting to a URL. The following code is a simple program that demonstrates
an API call to one of our projects ([AralDIF](AralDIF)):

```
import urllib2
import time

def dif(calltype, date1, date2, station):
    baseAPI = 'https://araldif.azurewebsites.net/api/'
    apiExtension = calltype + '?' + 'start=' + date1 + '&' + 'end=' + date2 + '&' + 'station=' + station + '&'
    api_call = baseAPI + apiExtension
    print api_call
    t1 = time.time()
    u = urllib2.urlopen(api_call)
    t2 = time.time()
    data = u.read()
    t3 = time.time()
    print 'URL open required', t2 - t1, 'seconds; read() required', t3 - t2, 'seconds'
    return data

data = dif('gethydrograph', '1995-01-01', '2000-12-31', 'UCHKU')
print data[0:198]
```

The output of this program (the first 198 characters returned) is as follows: 

```
https://araldif.azurewebsites.net/api/gethydrograph?start=1995-01-01&end=2000-12-31&station=UCHKU&
URL open required 9.09429216385 seconds; read() required 0.0734670162201 seconds
DATE,FLOW
1995-01-01,93.787209
1995-01-02,90.740631
1995-01-03,87.948059
1995-01-04,85.219681
1995-01-05,82.500687
1995-01-06,79.934334
1995-01-07,77.52166
1995-01-08,75.218941
1995-01-09,73.028778
```

Note that establishing the connection required about 9 seconds and the data transfer less than one tenth of a second.

The importance of being able to write this code is high and can be understood as follows: 

If your research requires you to regularly go to an external data resource to make new data queries 
(updates, new ideas for looking at existing data and so on) then you traditionally carry this out by manual 
methods: Lots of clicking and dragging and waiting. The above Web Client demonstrates that this process can be 
automated; provided that the person maintaining the data service (in our example 'araldif.azurewebsites.net') 
has built and maintained their side of the automation contract. 
