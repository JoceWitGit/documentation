
## Mounting the Attached Volume

To check if there is an attached volume, log on (ssh) onto your EC2 instance (Original recipe located [here](http://maplpro.blogspot
.com/2012/05/how-to-mount-ebs-volume-into-ec2-ubuntu.html). 

```
First see if it is attached with:

```
>> sudo fdisk -l
Disk /dev/xvdc: 10.7 GB, 10737418240 bytes
```

Then format it (if you haven't already done it)
```
>> sudo mkfs -t ext4 /dev/xvdc
```

Create dir where it will be mounted:
```
>>mkdir /data
```

That's it you can mount it:
```
>>sudo mount /dev/xvdc /data
```

Check if it has been mounted correctly with:
```
>>mount -l
/dev/xvdc on /data type ext4 (rw)
```

Make it to mount automatically on system start

```
>>sudo vim  /etc/fstab
```

and add this:

```
/dev/xvdc /data auto defaults,nobootwait 0 0
```

That's it. Make sure your read and write permissions are set accordingly using chmod. 

## What is the Snapshot ID?

Here is a screen capture of some volumes:

![ec20012](/documentation/images/aws/aws_ec20012.png)

Each is attached to an EC2 instance. Notice these have a snapshot ID. This means that these volumes were created from a snapshot, for example from an 
AMI = Snapshot + instructions. It does not mean that this snapshot still exists; or that if it did exist it would reflect what is actually in the 
restored volume. That volume probably has changed. So to explore these volumes:  Again we would ssh into the EC2 instance associated and go look at the file 
system.

In the case above, by the way, as noted earlier: These are all tell-tale Linux OS root volumes because the default on AWS Linux EC2 instances is 8GB. 

***Pro Tip: Returning to the snapshot table comment field ('Created by... in our example above): This can have anything 
in there (User defined) when the snapshot is of an EBS without this AMI association business.*** 

This concludes the overview of Snapshots and AMIs and the archaeological process of figuring out what is preserved on an artifact Snapshot.

## Key Pairs

In the Resource summary table there is an entry for Key Pairs. Let's cover what these are next. A Key Pair is both a public and 
a private key; and we will be primarily discussing the use of the private key file to authenticate into an AWS EC2 instance 
using the secure shell (ssh) protocol.

Start up an EC2 instance. You need an initial way of getting in via ssh. Rather than use a password let's use Key Pair authentication. 
I get the private Key file; and it contains JUST a private key: A long string of characters. Let's not publish this on Github. 

When I authenticate using PuTTY I set it to use this private key. PuTTY uses the '.ppk' version of the key but AWS only gives out a 
'.pem' version of that file. No problem: There is a separate application called PuTTYGen that does the conversion. So procedurally: 

1. Generate the EC2 instance
2. From the AWS Console: Get the key file associated.
3. Install both PuTTY and PuTTYGen (both will install in a PuTTY package)
4. Run PuTTYGen and convert the key file from .pem to .ppk format
5. Run PuTTY and use the .ppk file to log in to the instance.

To ssh to this EC2 instance I will need to know what username to enter.  This can vary from one EC2 instance type (OS) to another. 
For example on an AWS-styled Linux machine the user name is ec2-user. On an AWS EC2 Ubuntu instance the username is ubuntu. 

Now I have logged in to the machine using ssh. I can sudo anything I want. Success.

How do I log in in the future? How do others log in? Three options: 

1. I can use the key that I have and/or give that key to someone else. 
2. I can generate a new key on that machine and share that key. This has nothing to do with AWS. I could do 
it with a script for example, using Linux commands. 
3. I can enable logging in by username and password. 

Notice that ssh is a secure (encrypted) tunnel through which these keys are passing.

https://en.wikipedia.org/wiki/Secure_Shell

This security level is maintained as a separate effort by ssh / PuTTY. (PuTTY is the application and ssh is the cryptographic network protocol. 

## Ssh, PuTTY, scp and WinSCP

Now that we have identified PuTTY as the ssh-using application let's go a bit further. Ssh is also a Linux command for logging into another 
machine; so in a sense PuTTY is the Windows equivalent of the Linux ssh. Similarly there is a secure copy program in Linux called scp. The Windows analog is WinSCP. 

## More on Keys

Keys are actually generated in pairs: The public and private key pair are associated; and the public key can be openly shared. For more on this see 
https://en.wikipedia.org/wiki/Public-key_cryptography

On AWS I can only generate one key pair per machine. The private key recognition machinery is injected into the instance when it launches the first time; and 
I can start multiple instances using that same key. If I create an AMI and use that to generate many EC2 instances: Again just one private key provides 
access to all of them. One key can map to many EC2 instances in the context of AWS. 

## Keys Versus S3 Access Sharing

Let's take a moment to contrast Key-based access to an EC2 instance with the process of sharing files using S3 buckets. The latter is done 
using IAM permissions, specifically using a Bucket Policy. 

Sharing between AWS accounts is straightforward. If my friend has an AWS account then I just set that up in the S3 bucket policy by referring to his account 
number. So he has to send me that. 

Sharing with non-AWS-account holders is also easy and there are several options. If my collaborator has no AWS account 
I have three broad categories of approach: IAM User, Web Server and Signed URL.

IAM User method: I get an Access Key and a Secret Key. I do not think this is the same thing as a Key Pair but I could be 
proven wrong. I receive these two keys for example when I create a User. They reside in a single credential file. 
I click "Download Credentials" and there it is in ASCII. The file is in CSV format and includes a user name, an 
access key and a secret key (all strings). 

There are three ways of getting to the S3 bucket now for that person. 
- Third party tool: Cloudberry, Cyberduck, etcetera
- AWS command line interface (CLI)
- An API call
    - Notice this does NOT involve the Web Console. 
      - They can only use the AWS Web Console if I generate a password for them using IAM. 

Put a web server / web app in front of the S3 bucket. This pushes the problem down a level, so to speak.
 - Generate a signed URL
 - Gives access to one object during the time-to-live associated with that URL. 
 - This can be done on the CLI or in one of those applications (Cloudberry etc)
 - Look for the button that says 'Generate signed URL'

So now we have covered Key Pairs and differentiated Key Pair use from S3 access. 

### Mounting an EBS to your Instance

### FTP Setup and EC2 Instance

Overview: Create a virtual machine, install the ftp server and setup user accounts. Bonus: Bind your EC2 instance to an Elastic IP so you can reuse the same 
public IP even if your instance changes!

1. Sign up for a free AWS account [here](https://aws.amazon.com/free). 
Usage and free tier information available 
[here](https://aws.amazon.com/free/?sc_ichannel=ha&amp;sc_ipage=signin&amp;sc_iplace=body_link_text&amp;sc_icampaigntype=free_tier&amp;sc_icampaign=ha_en_free_tier_signin_2014_03). 

2.  [This recipe](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html) from AWS is straightforward. Print it out and don't skip a 
step. An EC2 (elastic compute cloud) is your virtual computing environment i.e. your virtual machine. This video by Microwave Sam expands on the EC2 setup.

    <iframe style="display: block; margin-left: auto; margin-right: auto;" src="//www.youtube.com/embed/wNr7YqjjzOY" width="425" height="350"></iframe>  

3.  Once your virtual machine is setup, you can access your "computer in the cloud" by securely tunneling in via the Terminal on your macbook, 
ssh on your Unix machines and Putty or other Unix environment emulator on Windows.

4.  You can now set up an FTP server on your virtual machine.

5.  The first solution [here on Stackoverflow](http://stackoverflow.com/questions/7052875/setting-up-ftp-on-amazon-cloud-server) is 
non-tortuous and really easy to follow. Thanks, clone45!

6.  You should now be able to use an FTP client to connect to your ftpserver.

7.  If you can't connect, check your directory permissions on your virtual machine!

8.  Again, follow instructions and don't skip a step!

### Elastic IPs

The annoying thing I've experienced with AWS is that every time you stop and restart an instance, you get assigned a new public DNS for 
your instance (e.g. public DNS = ec2-52-41-144-22.us-west-2.compute.amazonaws.com). 
You can get around this by associating ypur instance with an Elastic IP. Steps are outlined 
[here](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html). 
Once you've associated the Elastic IP with a running instance, you can ssh into the VM with the Elastic IP but using the previous public key generated 
for the instance. Don't forget to update the vsftpd.conf with your new Elastic IP address which is now your public address.

```
    > sudo vi /etc/vsftpd/vsftpd.conf
    pasv_address=<Elastic IP address>
    > sudo /etc/init.d/vsftpd restart
```

MS Azure on the other hand, let's you choose your on public DNS hostname which reduces the need for this workaround.

### DNS Hostnames

If you have your own registered domain, you can set your A-Record to point to the Elastic IP address of your instance. That gets rid of 
the unsightly public DNS that AWS assigns to you. Here's the example for cloudmaven.org (our domain registrar is Namecheap.com): 
![](https://raw.githubusercontent.com/amandalehr/cloudmaven/master/dns-eg.tiff)

An A-record points the hostname (here "compute") to the AWS instance Elastic IP (here "52.41.144.22"). I 
can then ssh into my compute instance using ec2-user@compute.cloudmaven.org. You can also set up similarly an A record called ftp that 
points to the elastic IP of your ftp server instance to allow ftp access into say ftp.cloudmaven org 

